<!doctype html>
<html lang="en">
<head>

  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta property="og:image" content="static/images/nanogpt-dalle.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/5.0.0-alpha1/css/bootstrap.min.css" integrity="sha384-r4NyP46KrjDleawBgD5tp8Y7UzmLA05oM1iAEQ17CSuDqnUK2+k9luXQOfXJCJ4I" crossorigin="anonymous">
  <link rel="stylesheet" href="static/styles.css">
  <link href="https://fonts.googleapis.com/css?family=Quicksand" rel="stylesheet">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.14.0/css/all.css" integrity="sha384-HzLeBuhoNPvSl5KYnjx0BT+WB0QEEqLprO+NBkkk5gbc67FTaL7XIGa2w1L0Xbgc" crossorigin="anonymous">

  <title>johncollins.ai</title>

  <!-- Optional JavaScript -->
  <!-- jQuery first, then Popper.js, then Bootstrap JS -->
  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.16.2/dist/umd/popper.min.js" integrity="sha384-ZRQgMf+zD5HtB5x8yhJ4y4Y4YO/7fMeRX/PV/v2t+5Dt7FJ8NpW4LN3ZYpDV7yoA" crossorigin="anonymous"></script>
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/5.0.0-alpha1/css/bootstrap.min.css" integrity="sha384-r4NyP46KrjDleawBgD5tp8Y7UzmLA05oM1iAEQ17CSuDqnUK2+k9luXQOfXJCJ4I" crossorigin="anonymous">
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/5.0.0-alpha1/js/bootstrap.min.js" integrity="sha384-oesi62hOLfzrys4LxRF63OJCXdXDipiYWBnvTl9Y9/TRlw5xlKIEHpNyvvDShgf/" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js"></script>

  <style>
    .container {
      max-width: 1140px;
    }

    body {
      background-color: black;
      color: white;
      font-family: "Quicksand", sans-serif;
    }

    .bg-black {
      background-color: #000000;
    }

    .border {
      border: 0.5px solid;
    }

    .border-white {
      border-color: #fff;
    } 

    .jumbotron-black-top {
          border-top: 50px solid #000;
    }

    .card-group-2 {
      display: grid;
      grid-template-columns: repeat(2, 1fr);
      grid-gap: 1rem;
    }

    .card-spacer {
    padding: 1rem;
    }
  </style>

</head>

<link rel="apple-touch-icon" sizes="180x180" href="static/images/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="static/images/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="static/images/favicon-16x16.png">
<link rel="manifest" href="static/images/site.webmanifest">
<link rel="shortcut icon" type="image/x-icon" href="static/images/favicon.ico">

<body id="myPage" data-spy="scroll" data-target=".navbar" data-offset="60">

  <!-- navbar -->
  <div class="container">
    <nav class="navbar navbar-expand-lg navbar-dark bg-transparent fixed-top">
      <div class="container-fluid">
        <a class="navbar-brand ml-2" href="{{ url_for('index') }}">johncollins.ai</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarNav">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item active">
              <a class="nav-link" href="https://twitter.com/johncollinsai" title="Follow me on Twitter" target="_blank"><i class="fab fa-twitter fa-lg fa-inverse fa-fw"></i></a>
            </li>
            <li class="nav-item active">
              <a class="nav-link" href="https://www.linkedin.com/in/johncollins-ai/" title="Connect with me on LinkedIn" target="_blank"><i class="fab fa-linkedin fa-lg fa-fw"></i></a>
            </li>
            <li class="nav-item ml-2">
              <a href="https://github.com/johncollinsai"><img src="https://github.githubassets.com/favicon.ico" title="Follow me on GitHub" alt="GitHub icon" style="filter: invert(100%);" target="_blank"></a>
            </li>
          </ul>
        </div>
      </div>
    </nav>
  </div>

  <div class="jumbotron jumbotron-fluid jumbotron-black-top">
    <div class="container">
      <h1 class="display-4">Personal work</h1>
      <p class="lead">I build and deploy AI at scale to solve intractable business problems, using DL/LLMs/GPTs with great AI UX. This is my personal site, where I share my own work and explore things that I find interesting. The code for my site and posts can be found on my <a href="https://github.com/johncollinsai" target-"_blank">GitHub</a>.</p>
    </div>
  </div>

  <!-- Most recent post prominantly featured at the top of main page -->
  <div class="container">
    <div class="card-group card-group card-spacer">
      <div class="card bg-black border border-secondary">
        <div class="row g-0">
          <div class="col-md-5">
            <img class="card-img-top" class="img-responsive" src="static/images/volgpt-image-jenny-saville-1.png" alt="Card image cap">
          </div>
          <div class="col-md-7">
            <div class="card-body">
              <h4 class="text-white">How does a GPT compare to a stochastic volatility model when asked to predict volatility?</h4>
                <p class="card-text">Earlier in my career I was a quantitative risk manager and built models where the input and output modalities were numbers. For example, I implemented the Heston stochastic volatility model to obtain certain dynamics of a stock's price from two stochastic differential equations <p>\( dS(t) = \mu S(t) dt + \sqrt{v(t)} S(t) dW_1(t) \)</p> and <p>\( dv(t) = \kappa (\theta - v(t)) dt + \sigma \sqrt{v(t)} dW_2(t) \)</p>. I would also back out implied vols and use the asset price paths to compute things like expected shortfall. However, with AI now and specifically models like the GPTs behind ChatGPT, we have many more permutations of input and output modalities, including text-to-image such as OpenAI's <a href="https://labs.openai.com/" target="_blank">DALL·E</a>, and Google Brain's text-to-video <a href="https://imagen.research.google/" target="_blank">Imagen</a>.</p>
                <p class="card-text">So what happens if I ask one of the powerful new GPT models to solve a problem that is normally handled by a number-to-number model like the Heston? In this post I use <a href="https://johncollinsai-nanogpt-voqqf4ls3a-as.a.run.app" target="_blank">my implementation</a> of Karpathy's NanoGPT and the extraordinary new GPT4 model to obtain volatility predictions.  The results are remarkable ... Please read on.</p>
                <a href="https://johncollinsai-gpt4-voqqf4ls3a-as.a.run.app" target="_blank" class="card-link">Continue reading ...</a>
                <p class="card-text"><small class="text-muted">Image prompt: Anish Kapoor observes GPT4 do fantastic things. Model: DALL·E 2</small></p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- Older posts organized in single-card rows underneath the most recent post -->
  <div class="container">
    <div class="card-group card-group card-spacer">
      <div class="card bg-black border border-secondary">
        <div class="row g-0">
          <div class="col-md-5">
            <img class="card-img-top" class="img-responsive" src="static/images/volgpt-image-jenny-saville.png" alt="Card image cap">
          </div>
          <div class="col-md-7">
            <div class="card-body">
              <h4 class="text-white">Predicting volatility with NanoGPT</h4>
                <p class="card-text">In this post, I train <a href="https://johncollinsai-nanogpt-voqqf4ls3a-as.a.run.app" target="_blank">my implementation</a> of Karpathy's NanoGPT, on high-frequency (tick-by-tick) data for <a href="https://www.google.com/search?q=aapl&oq=AAPL&aqs=chrome.0.0i512l5j69i61l3.1590j1j9&sourceid=chrome&ie=UTF-8" target="_blank">Apple</a> (Apple Inc., NASDAQ, ticker: AAPL), and <a href="https://www.google.com/search?q=jpm+stock+price&oq=JPM+stock+pri&aqs=chrome.0.0i512j69i57j0i512l8.4577j1j9&sourceid=chrome&ie=UTF-8" target="_blank">JP Morgan</a> (JPMorgan Chase & Co., NYSE, ticker: JPM) to see how a simple GPT performs as a volatility predictor. I also want to explore the use of a simple GPT for tasks, in this case volatility prediction, that have to date been typically performed by other models.  The application of a GPT to volatility prediction appears to be quite novel and the use of nanoGPT provides a great basis for an under-the-hood examination.</p>
                <p class="card-text">The code for this post can be found as always on <a href="https://github.com/johncollinsai/vogpt" target="_blank">my GitHub</a> and is arranged in two python files, one for input data, and one for NanoGPT.  A Jupyter notebook provides commentary, statistical analysis, and visualizations. NanoGPT does a pretty good job of volatility forecasting, which I think is very interesting ... </p>
                <a href="https://johncollinsai-volgpt-post-temp-voqqf4ls3a-as.a.run.app" target="_blank" class="card-link">Continue reading ...</a>
                <p class="card-text"><small class="text-muted">Image prompt: Two young people are observing volatile stock price movements.  They are seen by Jenny Saville. Model: DALL·E 2</small></p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="container">
    <div class="card-group card-group card-spacer">
      <div class="card bg-black border border-secondary">
        <div class="row g-0">
          <div class="col-md-5">
            <img class="card-img-top" class="img-responsive" src="static/images/nanogpt-dalle.png" alt="Card image cap">
          </div>
          <div class="col-md-7">
            <div class="card-body">
              <h4 class="text-white">Building a GPT</h4>
                <p class="card-text">I built and trained a Generative Pretrained Transformer (GPT), the same class of model behind <a href="https://chat.openai.com/chat" target="_blank">ChatGPT</a>, <a href="https://blog.google/technology/ai/bard-google-ai-search-updates/" target="_blank">Bard</a>, and <a href="https://www.bing.com/new" target="_blank">Bing</a>, but in my case a much simpler version.  GPTs are Large Language Models, in turn deep learning neural network architectures. GPTs are pre-trained on large amounts of text data using unsupervised learning. This pre-training step is crucial, as it enables the models to perform well on a variety of downstream natural language processing tasks without requiring large amounts of task-specific training data.</p>
                <p class="card-text">I followed <a href="https://www.youtube.com/watch?v=kCc8FmEb1nY" target="_blank">Karpathy's approach</a>, which helped me gain a better understanding of how GPTs work under the hood. I examined through construction the transformer architecture and returned to the seminal AI papers <a href="https://arxiv.org/abs/1706.03762" target="_blank">Attention Is All You Need</a>, which introduced the transformer architecture, and the GPT-3 paper <a href="https://arxiv.org/abs/2005.14165" target="_blank">Language Models are Few-Shot Learners</a>.  Overall, this post is a hands-on exploration of GPTs and the transformer architecture, with the goal of insight into how these models can be used commercially.</p>
                <a href="https://johncollinsai-nanogpt-voqqf4ls3a-as.a.run.app" target="_blank" class="card-link">Continue reading for the takeaways from this post ...</a>
                <p class="card-text"><small class="text-muted">Image prompt: Knowledge in the style of Egon Schiele. Model: DALL·E</small></p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="container">
    <div class="card-group card-group card-spacer">
      <div class="card bg-black border border-secondary">
        <div class="row g-0">
          <div class="col-md-5">
            <img class="card-img-top" class="img-responsive" src="static/images/lstm-dalle.png" alt="Card image cap">
          </div>
          <div class="col-md-7">
            <div class="card-body">
              <h4 class="text-white">LSTM</h4>
                <p class="card-text">I devote considerable effort in this post to a mathematical enunciation of LSTM, based upon the framework set out by Sherstinsky. A thorough derivation of the LSTM network is generally skipped in finance deep learning literature that features the LSTM. </p>
                <p class="card-text">I seek to understand each aspect of the operation of RNN and LSTM's elegant and effective systems in considerable depth. I describe firstly the RNN, followed by its evolution to the LSTM form, much more completely than is usually the case in finance DL papers.  These include unrolling the RNN, the motivations for the LSTM, namely managing the phenomena of vanishing gradients, and the subsequent mechanics of learning, which are the forward and backward passes and gradient descent.</p>
                <a href="https://johncollinsai-lstm-voqqf4ls3a-as.a.run.app" target="_blank" class="card-link">Continue reading ...</a>
                <p class="card-text"><small class="text-muted">Image prompt: Long and short term memories volatility, with style. Model: DALL·E</small></p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="container">
    <div class="card-group card-group card-spacer">
      <div class="card bg-black border border-secondary">
        <div class="row g-0">
          <div class="col-md-5">
            <img class="card-img-top" class="img-responsive" src="static/images/high-frequency-data-dalle.png" alt="Card image cap">
          </div>
          <div class="col-md-7">
            <div class="card-body">
              <h4 class="text-white">High Frequency Data</h4>
                <p class="card-text">In this post I discuss the preparation of high frequency datasets for Apple (Apple Inc., NASDAQ, ticker: AAPL), JPM (JPMorgan Chase & Co., NYSE, ticker: JPM), and the EURUSD currency pair. I use volatility prediction as my problem setting because the second moment dominates.</p>
                <p class="card-text">Careful data cleaning is one of the most important aspects of working with high frequency data and it is not always straightforward to construct a time series of interest from raw tick data. The methods I employ to prepare the data and compute a returns series are therefore are not trivial. I shall use these datasets a lot, so a thorough exposition of the steps taken is important. I hope to show, amongst other things, that simply fitting a time series of asset prices to a deep learning neural network, without proper consideration of the data itself and what it means, is a necessary but not sufficient condition for robust results. Put another way, when we obtain a prediction from our model, how certain can we be that what we observe is signal and not noise.</p>
                <a href="https://johncollinsai-high-frequency-data-voqqf4ls3a-as.a.run.app" target="_blank" class="card-link">Continue reading ...</a>
                <p class="card-text"><small class="text-muted">Image prompt: High frequency datasets in the style of benoit mandelbrot. Model: DALL·E</small></p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="container">
    <div class="card-group card-group card-spacer">
      <div class="card bg-black border border-secondary">
        <div class="row g-0">
          <div class="col-md-5">
            <img class="card-img-top" class="img-responsive" src="static/images/deep-learning-finance-dalle.png" alt="Card image cap">
          </div>
          <div class="col-md-7">
            <div class="card-body">
              <h4 class="text-white">Deep Learning in Finance</h4>
                <p class="card-text">In this post I discuss some of the papers I have read and found useful when considering deep learning in finance. I discuss academic literature here because a rigorous consideration of deep learning in finance is important, imho. This is my attempt at that and I hope it provides some useful background and context to my subsequent posts. This post was written around 2020-1, so is not particularly current. However, it covers important ground that is foundational.</p>
                <p class="card-text">This post is identical to <a href="https://github.com/johncollinsai/dlf" target="_blank">johncollinsai/dlf</a>. However, this post is deployed via Voila, whereas the other is deployed as html via a flask app. I think the voila deployment works better and thought the contrast between the two was interesting, hence having both up, for comparison. The code for both can be found on my github, <a href="https://github.com/johncollinsai/dlf" target="_blank">here</a> and <a href="https://github.com/johncollinsai/deep-learning-finance" target="_blank">here</a>.</p>
                <a href="https://johncollinsai-deep-learning-finance-voqqf4ls3a-as.a.run.app" target="_blank" class="card-link">Continue reading ...</a>
                <p class="card-text"><small class="text-muted">Image prompt: Billions of financial data points in the style of Lucian Freud. Model: DALL·E</small></p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- Footer -->
  <div class="container-fluid bg-black py-3">
    <div class="row">
      <div class="col text-center text-white">
        <p>&copy; 2023 johncollins</p>
      </div>
    </div>
  </div>

</body>
</html>

