<!DOCTYPE html>
<html lang="en">
<head>

    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta property="og:image" content="static/images/greg-userguide.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta name="title" content="https://johncollinsai-greg-voqqf4ls3a-as.a.run.app/">
    <meta name="description" content="AI analyst for due diligence">
    <meta property="og:title" content="AI analyst for due diligence">
    <meta property="og:description" content="AI analyst for due diligence">
    <meta property="og:url" content="https://johncollinsai-greg-voqqf4ls3a-as.a.run.app/">
    <meta property="og:type" content="website">
    <meta property="og:site_name" content="https://johncollinsai-greg-voqqf4ls3a-as.a.run.app/">
    <meta property="og:image" content="https://johncollinsai-greg-voqqf4ls3a-as.a.run.app/app/static/images/greg-userguide.png">
    <meta property="og:image:secure_url" content="https://johncollinsai-greg-voqqf4ls3a-as.a.run.app/app/static/images/greg-userguide.png">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="https://johncollinsai-greg-voqqf4ls3a-as.a.run.app/">
    <meta name="twitter:description" content="AI analyst for due diligence">
    <meta name="twitter:image" content="https://johncollinsai-greg-voqqf4ls3a-as.a.run.app/app/static/images/greg-userguide.png">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="https://johncollinsai-greg-voqqf4ls3a-as.a.run.app/app/static/images/greg-userguide.png">
  
    <title>AI analyst for due diligence</title>
   
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/5.0.0-alpha1/css/bootstrap.min.css" integrity="sha384-r4NyP46KrjDleawBgD5tp8Y7UzmLA05oM1iAEQ17CSuDqnUK2+k9luXQOfXJCJ4I" crossorigin="anonymous">
    <link rel="stylesheet" href="static/styles.css">
    <link href="https://fonts.googleapis.com/css?family=Quicksand" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.14.0/css/all.css" integrity="sha384-HzLeBuhoNPvSl5KYnjx0BT+WB0QEEqLprO+NBkkk5gbc67FTaL7XIGa2w1L0Xbgc" crossorigin="anonymous">
  
    <!-- JavaScript -->
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.16.2/dist/umd/popper.min.js" integrity="sha384-ZRQgMf+zD5HtB5x8yhJ4y4Y4YO/7fMeRX/PV/v2t+5Dt7FJ8NpW4LN3ZYpDV7yoA" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/5.0.0-alpha1/css/bootstrap.min.css" integrity="sha384-r4NyP46KrjDleawBgD5tp8Y7UzmLA05oM1iAEQ17CSuDqnUK2+k9luXQOfXJCJ4I" crossorigin="anonymous">
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/5.0.0-alpha1/js/bootstrap.min.js" integrity="sha384-oesi62hOLfzrys4LxRF63OJCXdXDipiYWBnvTl9Y9/TRlw5xlKIEHpNyvvDShgf/" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js"></script>
  
    <!-- Favicon -->
    <link rel="apple-touch-icon" sizes="180x180" href="static/images/greg-app-favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="static/images/greg-app-favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="static/images/greg-app-favicon/favicon-16x16.png">
    <link rel="manifest" href="static/images/greg-app-favicon/site.webmanifest">
    <link rel="shortcut icon" type="image/x-icon" href="static/images/greg-app-favicon/favicon.ico">
    <a href="https://johncollinsai-greg-voqqf4ls3a-as.a.run.app/"><img src="https://johncollinsai-greg-voqqf4ls3a-as.a.run.app/static/images/greg-app-favicon/favicon.ico" alt="Favicon" style="display:none;"></a>
  
    <!-- Include CSS file -->
    <link rel="stylesheet" href="/static/css/style.css">
  
    <!-- Include error handling file -->
    <script src="/static/js/errorHandling.js"></script>
  
    <!-- Include JavaScript file -->
    <script src="/static/js/scripts.js"></script>
    
    <!-- Include Google Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">

</head>

<body id="myPage" data-spy="scroll" data-target=".navbar" data-offset="60">

<!-- navbar -->
<nav class="navbar navbar-expand-lg fixed-top navbar-custom">
  <div class="container">
    <a class="navbar-brand ml-2 text-light" href="{{ url_for('index') }}">Greg Hallahan demo</a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item ml-2">
          <a href="https://github.com/johncollinsai"><img src="https://github.githubassets.com/favicon.ico" title="github repos" alt="GitHub icon" style="filter: invert(100%);" target="_blank"></a>
        </li>
      </ul>
    </div>
  </div>
</nav>

<!-- Title -->
<div class="jumbotron jumbotron-fluid jumbotron-black-top" style="margin-bottom: 75px;">
  <div class="container">
    <h1 class="display-4 text-center h1-margin-top h1-margin-bottom text-blue">AI analyst for due diligence user guide </h1>
  </div>
</div>

<!-- TL;DR -->
<div class="container">
  <h2 class="margin-top-custom text-white">TL;DR</h2>
  <p>LLMs increasingly dominate artificial intelligence. As always, I will present a specific example of fine-tuning a LLM to illustrate what I wish to say and provide full access to the source code on <a href="https://github.com/johncollinsai" target-"_blank">my GitHub</a>.  However, for now, I want to set the scene. In this post I set out various approaches to leveraging pretrained LLMs for new tasks, including in-context learning, finetuning, parameter-efficient finetuning, quantization, and reinforcement learning with human feedback. These approaches offer different ways to optimize model performance while minimizing computational costs.</p>
  <ul>
    <li>Finetuning all layers of a pretrained LLM remains the preferred approach for adapting models to new target tasks, but alternative strategies provide resource-efficient alternatives.</li>
    <li>In-context learning allows for task-specific interactions without direct model access, while indexing enables LLMs to function as information retrieval systems.</li>
    <li>Feature-based approaches offer effective means of adapting LLMs.</li>
    <li>Parameter-efficient finetuning techniques optimize performance while minimizing computational costs, making them especially valuable for larger models.</li>
    <li>Reinforcement learning with human feedback enhances LLM performance by incorporating human preferences through a combination of supervised and reinforcement learning methods.</li>
  </ul>
</div>

<!-- Intro -->
<div class="container">
  <h2 class="margin-top-custom text-white">Introduction</h2>
  <p>The growing significance of large language models (LLMs) in the field of artificial intelligence has led to an increasing need for efficient and effective utilization strategies. Two prominent methods for leveraging pretrained LLMs in new tasks are in-context learning and finetuning. In-context learning enables specific or novel tasks without further training by providing target examples through input prompts. On the other hand, finetuning involves adapting a pretrained LLM to a target task, and this post explores three conventional approaches to achieve this. Additionally, it delves into parameter-efficient finetuning techniques and reinforcement learning with human feedback as alternative strategies for optimizing LLM performance.</p>
</div>

<!-- promtengineering webapp -->
<section class="bg-black py-5">
  <div class="container">
    <div class="content-wrapper">
      <h2 class="text-center my-4 text-purple">AI analyst for due diligence</h2>
      <p class="text-center text-light-grey">We can use the webapp below to see how prompt engineering alters a model's response. The same language model is prompted with the company name.  On the left the prompt is passed directly to the model, whilst on the right it is engineered to obtain a more targeted response.</p>
      <p></p> <!-- empty paragraph for spacing -->
      <p></p> <!-- empty paragraph for spacing -->
      <div class="embed-responsive embed-responsive-16by9">
        <iframe id="predefined-question" class="embed-responsive-item" src="https://analyst-gpt.ai/" allowfullscreen></iframe>
      </div>
    </div>
  </div>
</section>

<!-- RESPONSIBLE AI -->
<section class="container-fluid pt-4 pb-5" style="background-color: #6F42C1; border: none;">
  <div class="container">
    <h2 class="text-center my-4 text-white">Responsible AI</h2>
    <div class="row justify-content-center" style="display: flex; align-items: stretch;">
      
      <!-- Card -->
      <div class="col-md-10 d-flex align-items-stretch">
        <div class="card bg-transparent custom-card custom-border">
          <div class="card-body text-light">
            <p>I built the AI chatbot opposite, which employs <a href="https://labs.openai.com/" target="_blank">OpenAI's GPT-4</a> language model to generate company-specific analyses. Select a report type (business, investigation, finance), input a valid company name, and the AI generates a tailored report. Notice the application of rigorous input validation and specific response boundaries, a cornerstone of responsible AI.</p>
            <p>Key principles of responsible AI implementation include:</p>
            <ul>
              <li><strong>Misuse Prevention:</strong> Input validation blocks harmful or inappropriate AI outputs and potential misuse.</li>
              <li><strong>User Safety:</strong> Techniques like input validation safeguard sensitive personal information, aligning with privacy laws.</li>
              <li><strong>Output Quality:</strong> Prompt engineering steers the AI to generate detailed, accurate responses, in this case specific types of analysis.</li>
              <li><strong>Ethical Guidelines Adherence:</strong> Input validation and prompt engineering ensure respect for societal norms and ethical guidelines.</li>
              <li><strong>Biases Mitigation:</strong> Careful input validation and prompt engineering can control amplification of existing biases.</li>
            </ul>
            <p>This AI chatbot therefore illustrates how input validation and prompt engineering are crucial in maintaining responsible, safe, and high-quality AI outputs.</p>
          </div>
        </div>
      </div>
    
    </div>
  </div>
</section>

<!-- In-Context Learning and Indexing -->
<div class="container">
  <h2 class="margin-top-custom text-white">In-Context Learning and Indexing</h2>
  <p>In-context learning allows users to leverage pretrained LLMs for specific tasks without requiring direct access to the model. By providing a few task-related examples in the input prompt, the LLM can generate appropriate responses. In situations where direct model access is limited, such as through an API, in-context learning is the obvious approach. An extension of this concept is hard prompt tuning, which involves modifying input words to improve output quality. Alternatively, soft prompt tuning offers a differentiable version of prompt modification.</p>
</div>

<!-- Finetuning Approaches -->
<div class="container">
  <h2 class="margin-top-custom text-white">Finetuning Approaches</h2>
  <p>Finetuning enables adaptation of pretrained LLMs to target tasks by updating model parameters. The feature-based approach involves extracting output embeddings from the pretrained LLM, using them as input features for training a separate classification model. This approach, commonly used for embedding-focused models like BERT, can also be applied to generative models like GPT. A popular variation of the feature-based approach focuses on training only the newly added output layers while keeping the pretrained LLM parameters frozen. An alternative approach entails updating all layers of the pretrained LLM to achieve superior modeling performance. Although it incurs higher computational costs, it generally outperforms. The choice between the different approaches depends on the target task and domain similarity to the pretrained dataset.</p>
</div>

<!-- Parameter-Efficient Finetuning -->
<div class="container">
  <h2 class="margin-top-custom text-white">Parameter-Efficient Finetuning</h2>
  <p>Parameter-efficient finetuning techniques (PEFT) are valuable for optimizing LLM performance while minimizing computational and resource requirements. These techniques introduce a small number of additional parameters for finetuning, reducing the need to train the entire model. Approaches such as prefix tuning, adapters, and low-rank adaptation modify multiple layers, yielding better predictive performance at a low cost. PEFT is particularly relevant when working with larger models that strain GPU memory capacity.</p>
</div>

<!-- Quantization -->
<div class="container">
  <h2 class="margin-top-custom text-white">Quantization</h2>
  <p>A quantized LLM is a compressed version of the original LLM that uses lower-precision data types for weights and activations. There are several approaches to model quantization for LLMs, including post-training quantization, quantization-aware training, and hybrid quantization. Post-training quantization involves training the LLM using floating-point data types and then quantizing the weights and activations to lower-precision data types post-training. Quantization-aware training involves quantizing the LLM during training, allowing the model to adapt to the reduced precision during training. Hybrid quantization combines both post-training quantization and quantization-aware training, allowing the LLM to adapt to lower-precision data types while also achieving good accuracy. Quantization can significantly improve the efficiency of LLM inference, enabling better real-time inference on large-scale datasets.</p>
</div>

<!-- Reinforcement Learning with Human Feedback -->
<div class="container">
  <h2 class="margin-top-custom text-white">Reinforcement Learning with Human Feedback</h2>
  <p>Reinforcement Learning with Human Feedback (RLHF) combines supervised learning and reinforcement learning to finetune pretrained LLMs. Humans provide feedback in the form of ranking or rating different model outputs, which is then used to train a reward model. The reward model guides the adaptation of the pretrained LLM to human preferences using reinforcement learning algorithms such as proximal policy optimization. This approach addresses the challenge of obtaining real-time feedback from humans, enhancing model performance in a more efficient manner.</p>
</div>

<!-- Technical -->
<div class="container">
  <h2 class="margin-top-custom text-white">Technical</h2>
  <p>The front end uses React for routing, state management, AJAX requests, and UI. A Flask app serves as an API to the React frontend.</p>
  <p>Best practices are strictly followed for both client-side (React) and server-side (Flask) security. JSON Web Tokens provide robust API authentication. Rate limiting and input validation protect not only against SQL injection, cross-site scripting, and other similar vulnerabilities, but also provide rigorous prompt boundaries, a cornerstone of responsible AI.</p>
  <p>I use various approaches to leveraging closed and pretrained LLMs, including in-context learning, finetuning, parameter-efficient finetuning, and quantization. I also use several ways to engineer prompts to get responses from models that best fit the specific requirement of due diligence. Few-shot approaches provide the model with a handful of examples to guide its output. An instruction element focuses on the task definition and influences the model's output through specificity, clarity, and context.</p>
  <p>The AI assistant is currently hosted on Google Cloud, utilizing Nginx as a web server and proxy, and orchestrated through Kubernetes (K8s) for managing the microservices, ensuring smooth deployment, scaling, and networking.</p>
</div>

<!-- Next steps -->
<div class="container">
  <h2 class="margin-top-custom text-purple">Next steps</h2>
    <p>I will train an open-source LLM, an implementation of LLaMA probably, on trades data and explore various risk management activities. In the set up I envisage, the LLM will replace the typical risk management stack that comprises ETL-database-analytics-visualisation.</p>
</div>

<!-- Additional reading -->
<div class="container">
  <h2 class="margin-top-custom text-purple">Additional reading</h2>
  <p>John Collins (2023). Personal website with several posts that might be useful, including articles on building and fine-tuning LLMs and GPTs, and prompt engineering. <a href="https://johncollins.ai" target-"_blank">johncollins.ai</a>.</p>
  <p>Lilian Weng (2023). Prompt Engineering. <a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/" target-"_blank">Lil'Log</a>.</p>
  <p>Wei, J., et al. (2022). Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. <a href="https://arxiv.org/abs/2201.11903" target-"_blank">arXiv:2201.11903</a>.</p>
</div>

<!-- Scripts -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>

<!-- Footer -->
<div class="container-fluid bg-black py-3">
  <div class="row">
    <div class="col text-center text-white">
      <p>&copy; 2023</p>
    </div>
  </div>
</div>
  
</body>
</html>

                           
